{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"2d4ee5a8e0e94503a164c8e5b19d6b9d","deepnote_cell_type":"markdown"},"source":"#### DivideFromHere","block_group":"e79136040ee1404b90eb8cc38b7eab88"},{"cell_type":"markdown","metadata":{"cell_id":"a9ffe0e5ce6746f3a158ee33fa98c297","deepnote_cell_type":"markdown"},"source":"# Experiment 3: Alpha-Beta Pruning Kane and Its randomization integrated with KAN","block_group":"d1ac738082134cc59047822783339279"},{"cell_type":"markdown","metadata":{"cell_id":"2c5bc15f72744ee596d42cac169c31b5","deepnote_cell_type":"markdown"},"source":"## Step 1: Overall Design\n### Objective:\nTo integrate the Kolmogorov-Arnold Networks (KAN) model to analyze and interpret the equivalence between deterministic and randomized versions of an Alpha-Beta Pruning algorithm-based chess AI named Kane.\n\n### Steps:\n#### Alpha-Beta Pruning Implementation:\n\n**Deterministic Alpha-Beta Pruning Implementation:**\n- Implement the deterministic version of the Alpha-Beta Pruning algorithm with heuristic evaluation for Kane.\n- Randomized Alpha-Beta Pruning Implementation:\n- Introduce randomization to the evaluation function and move selection to create a randomized version.\n#### Game Simulation:\n\n**Simulate Games:**\n- Simulate games using both the deterministic and randomized versions of Kane.\n- Collect performance metrics during each game, including additional metrics like evaluation score, branching factor, depth of search, move diversity, and exploration vs. exploitation.\n#### Data Collection and Analysis:\n\n- Collect and Aggregate Performance Metrics:\n- Collect evaluation consistency data.\n- Collect move stability data.\n- Collect search path data.\n#### Aggregate and analyze the results from multiple games.\n**Visualization:**\n\n- Plot Comparison Metrics and Equivalence Curves:\n- Plot comparison metrics to visualize the differences between the deterministic and randomized versions.\n- Plot the equivalence curve to show the relationship between the two versions.\n**Statistical Analysis:**\n\n- Perform Statistical Tests:\n- Perform statistical tests (t-test and F-test) to validate the results.\n- Plot the results of the statistical analysis.\n### KAN Model Integration:\n\n#### Define and Train KAN Model:\n\n- Define a custom KAN model architecture using PyTorch.\n- Train the KAN model on the aggregated data from both deterministic and randomized versions.\n- Evaluate the model's performance and track the equivalence score during training.\n#### Visualize KAN Model Results:\n\n- Visualize the dataset.\n- Extract and visualize the symbolic formula from the trained KAN model.\n- Plot the model's structure and equivalence data points.\n- Visualize the weights and biases of the trained KAN model.\n#### Verification and Conclusion:\n\n**Simulate Multiple Games:**\n- Run additional games to gather more data and plot the equivalence curve again.\n- Collect and aggregate performance metrics from the additional games.\n- Recalculate the means and standard deviations with combined data.\n- Plot the equivalence curve again with the combined data.","block_group":"e7275e7a25e742aa8f19765e4fc579e0"},{"cell_type":"markdown","metadata":{"cell_id":"6e971bed39c5461383f3921b3d616da2","deepnote_cell_type":"markdown"},"source":"## Step 2. Implement the deterministic version of the Alpha-Beta Pruning algorithm","block_group":"453f91a028e147db93be68a4a3145123"},{"cell_type":"code","metadata":{"source_hash":null,"deepnote_to_be_reexecuted":true,"cell_id":"7c3ac0baa8ed440a9c29242663744a02","deepnote_cell_type":"code"},"source":"import chess\nimport time\nfrom collections import defaultdict\nimport pandas as pd\nfrom IPython.display import clear_output, display, SVG\nimport chess.svg\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Deterministic Alpha-Beta Pruning Implementation\nclass KaneAlphaBetaDeterministic:\n    def __init__(self, board):\n        self.board = board\n        self.evaluation_consistency = defaultdict(list)\n        self.move_stability = defaultdict(int)\n        self.search_paths = defaultdict(list)\n\n    def heuristic_evaluation(self, board):\n        # Enhanced heuristic evaluation function\n        material_count = sum(1 if piece.color == chess.WHITE else -1 for piece in board.piece_map().values())\n        mobility_count = len(list(board.legal_moves))\n        piece_square_score = sum(1 if piece.color == chess.WHITE else -1 for piece in board.piece_map().values())\n        center_control_count = sum(1 if square in [chess.D4, chess.E4, chess.D5, chess.E5] else 0 for square, piece in board.piece_map().items())\n        score = material_count + mobility_count + piece_square_score + center_control_count\n        return score\n\n    def alpha_beta(self, board, depth, alpha, beta, is_maximizing_player):\n        position_hash = hash(board.board_fen())\n        if position_hash in self.evaluation_consistency and depth == 0:\n            return self.evaluation_consistency[position_hash][-1]  # Return the last stored evaluation for consistency\n        \n        evaluation = self.heuristic_evaluation(board) if depth == 0 or board.is_game_over() else (\n            self.alpha_beta_search(board, depth, alpha, beta, is_maximizing_player)\n        )\n        self.evaluation_consistency[position_hash].append(evaluation)\n        return evaluation\n\n    def alpha_beta_search(self, board, depth, alpha, beta, is_maximizing_player):\n        if is_maximizing_player:\n            max_eval = float('-inf')\n            for move in board.legal_moves:\n                board.push(move)\n                eval = self.alpha_beta(board, depth - 1, alpha, beta, False)\n                board.pop()\n                max_eval = max(max_eval, eval)\n                alpha = max(alpha, eval)\n                if beta <= alpha:\n                    break\n            return max_eval\n        else:\n            min_eval = float('inf')\n            for move in board.legal_moves:\n                board.push(move)\n                eval = self.alpha_beta(board, depth - 1, alpha, beta, True)\n                board.pop()\n                min_eval = min(min_eval, eval)\n                beta = min(beta, eval)\n                if beta <= alpha:\n                    break\n            return min_eval\n\n    def find_best_move_alpha_beta(self, depth=3):\n        position_hash = hash(self.board.board_fen())\n        best_move = None\n        best_value = float('-inf')\n        for move in self.board.legal_moves:\n            self.board.push(move)\n            move_value = self.alpha_beta(self.board, depth, float('-inf'), float('inf'), False)\n            self.board.pop()\n            if move_value > best_value:\n                best_value = move_value\n                best_move = move\n        self.move_stability[position_hash] += 1\n        return best_move\n\n    def track_search_path(self, board, move):\n        position_hash = hash(board.board_fen())\n        self.search_paths[position_hash].append(move.uci())\n","block_group":"de645627a9ce4c44b1f22ce1a4235012","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"33c23df50744479398242289259edb0a","deepnote_cell_type":"markdown"},"source":"## 3. Introduce randomization to the Alpha-Beta Pruning algorithm","block_group":"ab5936a7baf5422fa9135c21d9b9f221"},{"cell_type":"code","metadata":{"source_hash":null,"deepnote_to_be_reexecuted":true,"cell_id":"93d361a51f8b413682f95dbbbc504d38","deepnote_cell_type":"code"},"source":"# Pseudorandom Generator (PRG)\nclass PseudoRandom:\n    def __init__(self, seed):\n        self.state = seed\n\n    def random(self):\n        self.state = (1103515245 * self.state + 12345) % (2**31)\n        return self.state / (2**31)\n\n# Randomized Evaluation Function\nclass KaneAlphaBetaRandomization:\n    def __init__(self, board, seed):\n        self.board = board\n        self.prng = PseudoRandom(seed)\n        self.evaluation_consistency = defaultdict(list)\n        self.move_stability = defaultdict(int)\n        self.search_paths = defaultdict(list)\n\n    def heuristic_evaluation(self, board):\n        # Enhanced heuristic evaluation function with random component\n        material_count = sum(1 if piece.color == chess.WHITE else -1 for piece in board.piece_map().values())\n        mobility_count = len(list(board.legal_moves))\n        piece_square_score = sum(1 if piece.color == chess.WHITE else -1 for piece in board.piece_map().values())\n        center_control_count = sum(1 if square in [chess.D4, chess.E4, chess.D5, chess.E5] else 0 for square, piece in board.piece_map().items())\n        score = material_count + mobility_count + piece_square_score + center_control_count\n        random_adjustment = int((self.prng.random() - 0.5) * 10)  # Random adjustment between -5 and +5\n        return score + random_adjustment\n\n    def alpha_beta(self, board, depth, alpha, beta, is_maximizing_player):\n        position_hash = hash(board.board_fen())\n        if position_hash in self.evaluation_consistency and depth == 0:\n            return self.evaluation_consistency[position_hash][-1]  # Return the last stored evaluation for consistency\n        \n        evaluation = self.heuristic_evaluation(board) if depth == 0 or board.is_game_over() else (\n            self.alpha_beta_search(board, depth, alpha, beta, is_maximizing_player)\n        )\n        self.evaluation_consistency[position_hash].append(evaluation)\n        return evaluation\n\n    def alpha_beta_search(self, board, depth, alpha, beta, is_maximizing_player):\n        if is_maximizing_player:\n            max_eval = float('-inf')\n            for move in board.legal_moves:\n                board.push(move)\n                eval = self.alpha_beta(board, depth - 1, alpha, beta, False)\n                board.pop()\n                max_eval = max(max_eval, eval)\n                alpha = max(alpha, eval)\n                if beta <= alpha:\n                    break\n            return max_eval\n        else:\n            min_eval = float('inf')\n            for move in board.legal_moves:\n                board.push(move)\n                eval = self.alpha_beta(board, depth - 1, alpha, beta, True)\n                board.pop()\n                min_eval = min(min_eval, eval)\n                beta = min(beta, eval)\n                if beta <= alpha:\n                    break\n            return min_eval\n\n    def find_best_move_alpha_beta(self, depth=3):\n        position_hash = hash(self.board.board_fen())\n        best_move = None\n        best_value = float('-inf')\n        for move in self.board.legal_moves:\n            self.board.push(move)\n            move_value = self.alpha_beta(self.board, depth, float('-inf'), float('inf'), False)\n            self.board.pop()\n            if move_value > best_value:\n                best_value = move_value\n                best_move = move\n        self.move_stability[position_hash] += 1\n        return best_move\n\n    def track_search_path(self, board, move):\n        position_hash = hash(board.board_fen())\n        self.search_paths[position_hash].append(move.uci())\n","block_group":"92ee65b029f54fb7b01d54c918a38c17","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"ecd11beca6a749029b8e1ecbaec393f4","deepnote_cell_type":"markdown"},"source":"## 4. Simulate games using both deterministic and randomized algorithms","block_group":"497dc5d0d00c4460a71a149337e15054"},{"cell_type":"code","metadata":{"source_hash":null,"deepnote_to_be_reexecuted":true,"cell_id":"7c7bfbe0b44d43f7ba15b66f8755a886","deepnote_cell_type":"code"},"source":"# Function to calculate additional metrics\ndef calculate_metrics(board):\n    material_count = sum(1 if piece.color == chess.WHITE else -1 for piece in board.piece_map().values())\n    mobility_count = len(list(board.legal_moves))\n    piece_square_score = sum(1 if piece.color == chess.WHITE else -1 for piece in board.piece_map().values())\n    center_control_count = sum(1 if square in [chess.D4, chess.E4, chess.D5, chess.E5] else 0 for square, piece in board.piece_map().items())\n    return material_count, mobility_count, piece_square_score, center_control_count\n\ndef calculate_additional_metrics(board, move_scores, current_depth, is_exploratory):\n    evaluation_score = sum(move_scores) / len(move_scores) if move_scores else 0\n    branching_factor = len(list(board.legal_moves))\n    depth_of_search = current_depth\n    move_diversity = np.var(move_scores) if move_scores else 0\n    exploration_vs_exploitation = 1 if is_exploratory else 0\n    return evaluation_score, branching_factor, depth_of_search, move_diversity, exploration_vs_exploitation\n\n# Function to play the game with deterministic Alpha-Beta Pruning\ndef play_game_alpha_beta_deterministic(kane_alpha_beta, depth=3, max_moves=55, max_runtime=600):\n    steps, times, material_counts, mobility_counts, piece_square_scores, center_control_counts = [], [], [], [], [], []\n    move_list, evaluation_scores, branching_factors, depths_of_search, move_diversities, exploration_vs_exploitations = [], [], [], [], [], []\n    step_number = 1\n\n    start_time = time.time()\n    while not kane_alpha_beta.board.is_game_over() and step_number <= max_moves and (time.time() - start_time) <= max_runtime:\n        move_start_time = time.time()\n        best_move = kane_alpha_beta.find_best_move_alpha_beta(depth)\n        move_end_time = time.time()\n\n        kane_alpha_beta.board.push(best_move)\n        kane_alpha_beta.track_search_path(kane_alpha_beta.board, best_move)\n\n        move_list.append(best_move.uci())\n        steps.append(step_number)\n        times.append(move_end_time - move_start_time)\n\n        material_count, mobility_count, piece_square_score, center_control_count = calculate_metrics(kane_alpha_beta.board)\n        material_counts.append(material_count)\n        mobility_counts.append(mobility_count)\n        piece_square_scores.append(piece_square_score)\n        center_control_counts.append(center_control_count)\n\n        move_scores = [kane_alpha_beta.alpha_beta(kane_alpha_beta.board, depth, float('-inf'), float('inf'), False) for move in kane_alpha_beta.board.legal_moves]\n        evaluation_score, branching_factor, depth_of_search, move_diversity, exploration_vs_exploitation = calculate_additional_metrics(\n            kane_alpha_beta.board, move_scores, depth, False)\n        evaluation_scores.append(evaluation_score)\n        branching_factors.append(branching_factor)\n        depths_of_search.append(depth_of_search)\n        move_diversities.append(move_diversity)\n        exploration_vs_exploitations.append(exploration_vs_exploitation)\n\n        step_number += 1\n\n        clear_output(wait=True)\n        display(SVG(chess.svg.board(board=kane_alpha_beta.board, size=350)))\n\n        time.sleep(1)\n        print(f\"Move: {best_move}\")\n        print(f\"Step: {step_number}, Time: {move_end_time - move_start_time}, Material: {material_count}, Mobility: {mobility_count}, Piece-Square: {piece_square_score}, Center Control: {center_control_count}\")\n\n    data = {\n        'Step': steps,\n        'Time': times,\n        'Move': move_list,\n        'Material Count': material_counts,\n        'Mobility Count': mobility_counts,\n        'Piece-Square Score': piece_square_scores,\n        'Center Control Count': center_control_counts,\n        'Evaluation Score': evaluation_scores,\n        'Branching Factor': branching_factors,\n        'Depth of Search': depths_of_search,\n        'Move Diversity': move_diversities,\n        'Exploration vs Exploitation': exploration_vs_exploitations\n    }\n    df = pd.DataFrame(data)\n\n    print(\"Stop the game in advance!\")\n    print(f\"Result: {kane_alpha_beta.board.result()}\")\n    print(df)\n    return df\n\n# Initialize the boards and engines\nboard_deterministic = chess.Board()\nkane_deterministic = KaneAlphaBetaDeterministic(board_deterministic)\n\n# Simulate and run the deterministic game\nprint(\"Running deterministic game...\")\ndeterministic_results = [play_game_alpha_beta_deterministic(kane_deterministic)]\n\n# Function to play the game with randomized Alpha-Beta Pruning\ndef play_game_alpha_beta_randomized(kane_alpha_beta, depth=3, max_moves=55, max_runtime=600):\n    steps, times, material_counts, mobility_counts, piece_square_scores, center_control_counts = [], [], [], [], [], []\n    move_list, evaluation_scores, branching_factors, depths_of_search, move_diversities, exploration_vs_exploitations = [], [], [], [], [], []\n    step_number = 1\n\n    start_time = time.time()\n    while not kane_alpha_beta.board.is_game_over() and step_number <= max_moves and (time.time() - start_time) <= max_runtime:\n        move_start_time = time.time()\n        best_move = kane_alpha_beta.find_best_move_alpha_beta(depth)\n        move_end_time = time.time()\n\n        kane_alpha_beta.board.push(best_move)\n        kane_alpha_beta.track_search_path(kane_alpha_beta.board, best_move)\n\n        move_list.append(best_move.uci())\n        steps.append(step_number)\n        times.append(move_end_time - move_start_time)\n\n        material_count, mobility_count, piece_square_score, center_control_count = calculate_metrics(kane_alpha_beta.board)\n        material_counts.append(material_count)\n        mobility_counts.append(mobility_count)\n        piece_square_scores.append(piece_square_score)\n        center_control_counts.append(center_control_count)\n\n        move_scores = [kane_alpha_beta.alpha_beta(kane_alpha_beta.board, depth, float('-inf'), float('inf'), False) for move in kane_alpha_beta.board.legal_moves]\n        evaluation_score, branching_factor, depth_of_search, move_diversity, exploration_vs_exploitation = calculate_additional_metrics(\n            kane_alpha_beta.board, move_scores, depth, False)\n        evaluation_scores.append(evaluation_score)\n        branching_factors.append(branching_factor)\n        depths_of_search.append(depth_of_search)\n        move_diversities.append(move_diversity)\n        exploration_vs_exploitations.append(exploration_vs_exploitation)\n\n        step_number += 1\n\n        clear_output(wait=True)\n        display(SVG(chess.svg.board(board=kane_alpha_beta.board, size=350)))\n\n        time.sleep(1)\n        print(f\"Move: {best_move}\")\n        print(f\"Step: {step_number}, Time: {move_end_time - move_start_time}, Material: {material_count}, Mobility: {mobility_count}, Piece-Square: {piece_square_score}, Center Control: {center_control_count}\")\n\n    data = {\n        'Step': steps,\n        'Time': times,\n        'Move': move_list,\n        'Material Count': material_counts,\n        'Mobility Count': mobility_counts,\n        'Piece-Square Score': piece_square_scores,\n        'Center Control Count': center_control_counts,\n        'Evaluation Score': evaluation_scores,\n        'Branching Factor': branching_factors,\n        'Depth of Search': depths_of_search,\n        'Move Diversity': move_diversities,\n        'Exploration vs Exploitation': exploration_vs_exploitations\n    }\n    df = pd.DataFrame(data)\n\n    print(\"Stop the game in advance!\")\n    print(f\"Result: {kane_alpha_beta.board.result()}\")\n    print(df)\n    return df\n\n# Initialize the boards and engines\nboard_randomized = chess.Board()\nkane_randomized = KaneAlphaBetaRandomization(board_randomized, seed=42)\n\n# Simulate and run the randomized game\nprint(\"Running randomized game...\")\nrandomized_results = [play_game_alpha_beta_randomized(kane_randomized)]\n","block_group":"6179efa227484d73b27bfadbf2548d50","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"cbc807b7c8164d0b9069ecbc0f3106d7","deepnote_cell_type":"markdown"},"source":"","block_group":"5bebcea49b314c6996b3c1607d05dc4c"},{"cell_type":"markdown","metadata":{"cell_id":"d0998d0232c845c58e155cf74aab3f59","deepnote_cell_type":"markdown"},"source":"## 5. Collect and analyze performance metrics","block_group":"0f184c62ae724f5598c8ecf4d627fc26"},{"cell_type":"code","metadata":{"source_hash":null,"deepnote_to_be_reexecuted":true,"cell_id":"226a482861e84d40a9ff981309e5ae23","deepnote_cell_type":"code"},"source":"# Function to ensure all results are DataFrames and handle errors\ndef ensure_dataframe(result):\n    if isinstance(result, pd.DataFrame):\n        return result\n    try:\n        return pd.DataFrame(result)\n    except Exception as e:\n        print(\"Error converting to DataFrame:\", e)\n        return pd.DataFrame()\n\n# Convert results to DataFrames\ndeterministic_results = [ensure_dataframe(df) for df in deterministic_results]\nrandomized_results = [ensure_dataframe(df) for df in randomized_results]\n\n# Aggregate and analyze the results\ndef aggregate_metrics(results):\n    numeric_columns = ['Material Count', 'Mobility Count', 'Piece-Square Score', 'Center Control Count',\n                       'Evaluation Score', 'Branching Factor', 'Depth of Search', 'Move Diversity',\n                       'Exploration vs Exploitation']\n    \n    aggregated_data = pd.concat(results, ignore_index=True)\n    \n    mean_metrics = aggregated_data[numeric_columns].mean()\n    std_metrics = aggregated_data[numeric_columns].std()\n    \n    return mean_metrics, std_metrics, aggregated_data\n\n# Aggregate the results\ndeterministic_mean, deterministic_std, deterministic_data = aggregate_metrics(deterministic_results)\nrandomized_mean, randomized_std, randomized_data = aggregate_metrics(randomized_results)\n\n# Display the aggregated metrics\nprint(\"Deterministic Mean Metrics:\\n\", deterministic_mean)\nprint(\"Deterministic Std Metrics:\\n\", deterministic_std)\nprint(\"\\nRandomized Mean Metrics:\\n\", randomized_mean)\nprint(\"Randomized Std Metrics:\\n\", randomized_std)\n\n# Display move sequences and non-numeric data\nprint(\"\\nDeterministic Moves:\\n\", deterministic_data['Move'])\nprint(\"\\nRandomized Moves:\\n\", randomized_data['Move'])\n","block_group":"12632676804d437f918e548e09bcdd9e","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"9ca859ac4ec942928933f3535f4c48b7","deepnote_cell_type":"markdown"},"source":"## 6. Plot comparison metrics and equivalence curves","block_group":"45ec6ba760d44e7ba00de3ea997464fc"},{"cell_type":"code","metadata":{"source_hash":null,"deepnote_to_be_reexecuted":true,"cell_id":"9c88d952e1e1452380dba48e9feda986","deepnote_cell_type":"code"},"source":"# Plot comparison metrics\ndef plot_comparison_metrics(deterministic_mean, deterministic_std, randomized_mean, randomized_std):\n    metrics = deterministic_mean.index\n    x = range(len(metrics))\n\n    fig, axs = plt.subplots(2, 1, figsize=(14, 10))\n\n    # Plot means\n    axs[0].bar(x, deterministic_mean, width=0.4, label='Deterministic Mean', align='center')\n    axs[0].bar(x, randomized_mean, width=0.4, label='Randomized Mean', align='edge')\n    axs[0].set_xticks(x)\n    axs[0].set_xticklabels(metrics, rotation=45, ha='right')\n    axs[0].set_ylabel('Mean Value')\n    axs[0].set_title('Comparison of Mean Metrics')\n    axs[0].legend()\n\n    # Plot standard deviations\n    axs[1].bar(x, deterministic_std, width=0.4, label='Deterministic Std', align='center')\n    axs[1].bar(x, randomized_std, width=0.4, label='Randomized Std', align='edge')\n    axs[1].set_xticks(x)\n    axs[1].set_xticklabels(metrics, rotation=45, ha='right')\n    axs[1].set_ylabel('Standard Deviation')\n    axs[1].set_title('Comparison of Standard Deviation Metrics')\n    axs[1].legend()\n\n    plt.tight_layout()\n    plt.show()\n\n# Plot equivalence curve\ndef plot_equivalence_curve(deterministic_mean, deterministic_std, randomized_mean, randomized_std):\n    metrics = deterministic_mean.index\n    x = np.arange(len(metrics))\n\n    # Create figure and axis\n    fig, ax = plt.subplots(figsize=(14, 7))\n\n    # Plot deterministic means with error bars for std\n    ax.errorbar(x, deterministic_mean, yerr=deterministic_std, fmt='o-', label='Deterministic', color='blue', capsize=5)\n\n    # Plot randomized means with error bars for std\n    ax.errorbar(x, randomized_mean, yerr=randomized_std, fmt='o-', label='Randomized', color='green', capsize=5)\n\n    # Fill between for deterministic std\n    ax.fill_between(x, deterministic_mean - deterministic_std, deterministic_mean + deterministic_std, color='blue', alpha=0.2)\n\n    # Fill between for randomized std\n    ax.fill_between(x, randomized_mean - randomized_std, randomized_mean + randomized_std, color='green', alpha=0.2)\n\n    # Add title and labels\n    ax.set_title('Equivalence Curve for Deterministic and Randomized Alpha-Beta Algorithms')\n    ax.set_xlabel('Metrics')\n    ax.set_ylabel('Values')\n    ax.set_xticks(x)\n    ax.set_xticklabels(metrics, rotation=45, ha='right')\n\n    # Add legend\n    ax.legend()\n\n    # Show plot\n    plt.tight_layout()\n    plt.show()\n\n# Plot the comparison metrics\nplot_comparison_metrics(deterministic_mean, deterministic_std, randomized_mean, randomized_std)\n\n# Plot the equivalence curve\nplot_equivalence_curve(deterministic_mean, deterministic_std, randomized_mean, randomized_std)\n","block_group":"1ab5af9d965d43deb7c08bdf146e814d","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"1ed8739cdf92484a9fbb19d0de9333a7","deepnote_cell_type":"markdown"},"source":"## 7. Perform statistical tests","block_group":"576034fff805435fb3b6200a8a77d80d"},{"cell_type":"code","metadata":{"source_hash":null,"deepnote_to_be_reexecuted":true,"cell_id":"e75a051dfe3646f4917475dddbcb4765","deepnote_cell_type":"code"},"source":"from scipy.stats import ttest_ind, f_oneway\n\n# Function to perform statistical tests\ndef perform_statistical_tests(deterministic_metrics, randomized_metrics):\n    results = {}\n    for metric in deterministic_metrics.index:\n        t_stat, p_value_t = ttest_ind(deterministic_data[metric], randomized_data[metric], equal_var=False)\n        f_stat, p_value_f = f_oneway(deterministic_data[metric], randomized_data[metric])\n        results[metric] = {\n            't_stat': t_stat,\n            'p_value_t': p_value_t,\n            'f_stat': f_stat,\n            'p_value_f': p_value_f\n        }\n    return results\n\n# Perform statistical tests\nstatistical_results = perform_statistical_tests(deterministic_mean, randomized_mean)\n\n# Display the results\nfor metric, result in statistical_results.items():\n    print(f\"{metric}: t-statistic = {result['t_stat']}, p-value (t-test) = {result['p_value_t']}\")\n    print(f\"{metric}: f-statistic = {result['f_stat']}, p-value (F-test) = {result['p_value_f']}\\n\")\n\n# Plot statistical analysis results\ndef plot_statistical_analysis(statistical_results):\n    metrics = list(statistical_results.keys())\n    t_stats = [result['t_stat'] for result in statistical_results.values()]\n    p_values_t = [result['p_value_t'] for result in statistical_results.values()]\n\n    fig, axs = plt.subplots(2, 1, figsize=(14, 10))\n\n    # Plot t-statistics\n    axs[0].bar(metrics, t_stats, color='blue')\n    axs[0].set_xticks(metrics)\n    axs[0].set_xticklabels(metrics, rotation=45, ha='right')\n    axs[0].set_ylabel('t-statistic')\n    axs[0].set_title('t-statistic of Each Metric')\n\n    # Plot p-values (t-test)\n    axs[1].bar(metrics, p_values_t, color='green')\n    axs[1].set_xticks(metrics)\n    axs[1].set_xticklabels(metrics, rotation=45, ha='right')\n    axs[1].axhline(y=0.05, color='r', linestyle='--')\n    axs[1].set_ylabel('p-value (t-test)')\n    axs[1].set_title('p-value (t-test) of Each Metric')\n\n    plt.tight_layout()\n    plt.show()\n\n# Plot statistical analysis results\nplot_statistical_analysis(statistical_results)\n","block_group":"cab3ecdd7103492898938e61d33bebc8","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"f3b6c75a8c2040cbadf994059cafc04d","deepnote_cell_type":"markdown"},"source":"## 8. Run additional games to gather more data and plot the equivalence curve again","block_group":"fcd51133bf5b4438b79598712d9e6e1a"},{"cell_type":"code","metadata":{"source_hash":null,"deepnote_to_be_reexecuted":true,"cell_id":"dc326f0e905a48619cd42efed967c31e","deepnote_cell_type":"code"},"source":"# Run additional games to gather more data\ndef compare_alpha_beta_kane_versions(deterministic_kane, randomized_kane, depth=3, games=5, max_moves=55, max_runtime=600):\n    deterministic_results = []\n    randomized_results = []\n\n    for _ in range(games):\n        # Play game with deterministic Kane\n        deterministic_kane.board.reset()\n        deterministic_data = play_game_alpha_beta_deterministic(deterministic_kane, depth, max_moves, max_runtime)\n        deterministic_results.append(deterministic_data)\n\n        # Play game with randomized Kane\n        randomized_kane.board.reset()\n        randomized_data = play_game_alpha_beta_randomized(randomized_kane, depth, max_moves, max_runtime)\n        randomized_results.append(randomized_data)\n\n    return deterministic_results, randomized_results\n\n# Initialize the boards and engines\nboard_deterministic = chess.Board()\nkane_deterministic = KaneAlphaBetaDeterministic(board_deterministic)\n\nboard_randomized = chess.Board()\nkane_randomized = KaneAlphaBetaRandomization(board_randomized, seed=42)\n\n# Compare the two versions over multiple games\ndeterministic_results, randomized_results = compare_alpha_beta_kane_versions(kane_deterministic, kane_randomized)\n\n# Aggregate the results\ndeterministic_mean, deterministic_std, deterministic_data = aggregate_metrics(deterministic_results)\nrandomized_mean, randomized_std, randomized_data = aggregate_metrics(randomized_results)\n\n# Run additional games to gather more data\nadditional_games = 10\ndeterministic_results_additional, randomized_results_additional = compare_alpha_beta_kane_versions(kane_deterministic, kane_randomized, games=additional_games)\n\n# Aggregate the additional data\ndeterministic_mean_additional, deterministic_std_additional, deterministic_data_additional = aggregate_metrics(deterministic_results_additional)\nrandomized_mean_additional, randomized_std_additional, randomized_data_additional = aggregate_metrics(randomized_results_additional)\n\n# Combine the original and additional data\ncombined_deterministic_data = pd.concat([deterministic_data, deterministic_data_additional], ignore_index=True)\ncombined_randomized_data = pd.concat([randomized_data, randomized_data_additional], ignore_index=True)\n\n# Recalculate the means and standard deviations\ncombined_deterministic_mean, combined_deterministic_std = combined_deterministic_data.mean(), combined_deterministic_data.std()\ncombined_randomized_mean, combined_randomized_std = combined_randomized_data.mean(), combined_randomized_data.std()\n\n# Display the combined metrics\nprint(\"Combined Deterministic Mean Metrics:\\n\", combined_deterministic_mean)\nprint(\"Combined Deterministic Std Metrics:\\n\", combined_deterministic_std)\nprint(\"\\nCombined Randomized Mean Metrics:\\n\", combined_randomized_mean)\nprint(\"Combined Randomized Std Metrics:\\n\", combined_randomized_std)\n\n# Plot the equivalence curve again with combined data\nplot_equivalence_curve(combined_deterministic_mean, combined_deterministic_std, combined_randomized_mean, combined_randomized_std)\n","block_group":"1d22247c85484aa0ae008aadf4102e72","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"7d29b52e7c944f3cb7a5e6461003e5e1","deepnote_cell_type":"markdown"},"source":"## 9. KAN Integration for Alpha-Beta Pruning Kane\n### 9.1. Define a custom KAN model architecture using PyTorch","block_group":"b953edfe66184220a5c821fd8cfefa4e"},{"cell_type":"code","metadata":{"source_hash":null,"deepnote_to_be_reexecuted":true,"cell_id":"a5c7b8e1041e4ec0b61a088b7068b35c","deepnote_cell_type":"code"},"source":"class KANModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(KANModel, self).__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n        self.fc3 = nn.Linear(hidden_dim, output_dim)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        out = self.fc1(x)\n        out = self.relu(out)\n        out = self.fc2(out)\n        out = self.relu(out)\n        out = self.fc3(out)\n        return out\n","block_group":"398d0957231c49a9b102a1c5cc79d904","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"8dd6976ca2cf4692a5f269cb29eb375e","deepnote_cell_type":"markdown"},"source":"### 9.2 Train the KAN model on the collected data","block_group":"52f9b76fd73144c295d7d7475e3897cc"},{"cell_type":"code","metadata":{"source_hash":null,"deepnote_to_be_reexecuted":true,"cell_id":"be63f5af68d84de88c0b325f67174328","deepnote_cell_type":"code"},"source":"# Prepare the data for KAN model training\ndef prepare_data(deterministic_data, randomized_data):\n    X = deterministic_data[['Material Count', 'Mobility Count', 'Piece-Square Score', 'Center Control Count']].values\n    y = randomized_data[['Material Count', 'Mobility Count', 'Piece-Square Score', 'Center Control Count']].values\n    return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n\nX, y = prepare_data(combined_deterministic_data, combined_randomized_data)\n\n# Initialize the KAN model\ninput_dim = X.shape[1]\nhidden_dim = 128\noutput_dim = y.shape[1]\nkan_model = KANModel(input_dim, hidden_dim, output_dim)\n\n# Define the loss function and optimizer\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(kan_model.parameters(), lr=0.001)\n\n# Train the KAN model\nnum_epochs = 500\nfor epoch in range(num_epochs):\n    kan_model.train()\n    optimizer.zero_grad()\n    outputs = kan_model(X)\n    loss = criterion(outputs, y)\n    loss.backward()\n    optimizer.step()\n\n    if (epoch+1) % 50 == 0:\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n","block_group":"4c5e0292fac8481b87bca1c6c9ddac67","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"0ce64f2b4eb8429b8db01e17e0268f8d","deepnote_cell_type":"markdown"},"source":"### 9.3 3. Evaluate the model's performance and track the equivalence score during training","block_group":"a56fa1ca3f4e49fb9a31a41011475563"},{"cell_type":"code","metadata":{"source_hash":null,"deepnote_to_be_reexecuted":true,"cell_id":"cde05bbc392d4678b8c74c83a54f24b1","deepnote_cell_type":"code"},"source":"# Evaluate the KAN model\nkan_model.eval()\nwith torch.no_grad():\n    predictions = kan_model(X)\n    equivalence_score = criterion(predictions, y).item()\n\nprint(f'Equivalence Score: {equivalence_score:.4f}')\n\n# Visualization of dataset\nplt.figure(figsize=(10, 6))\nplt.scatter(X[:, 0], y[:, 0], label='Material Count')\nplt.scatter(X[:, 1], y[:, 1], label='Mobility Count')\nplt.scatter(X[:, 2], y[:, 2], label='Piece-Square Score')\nplt.scatter(X[:, 3], y[:, 3], label='Center Control Count')\nplt.legend()\nplt.xlabel('Deterministic Data')\nplt.ylabel('Randomized Data')\nplt.title('Deterministic vs Randomized Metrics')\nplt.show()\n\n# Plot the equivalence curve to show the relationship between the deterministic and randomized versions\nplt.figure(figsize=(10, 6))\nplt.plot(range(len(X)), predictions[:, 0], label='Material Count Prediction', linestyle='--')\nplt.plot(range(len(X)), y[:, 0], label='Material Count Actual')\nplt.plot(range(len(X)), predictions[:, 1], label='Mobility Count Prediction', linestyle='--')\nplt.plot(range(len(X)), y[:, 1], label='Mobility Count Actual')\nplt.plot(range(len(X)), predictions[:, 2], label='Piece-Square Score Prediction', linestyle='--')\nplt.plot(range(len(X)), y[:, 2], label='Piece-Square Score Actual')\nplt.plot(range(len(X)), predictions[:, 3], label='Center Control Count Prediction', linestyle='--')\nplt.plot(range(len(X)), y[:, 3], label='Center Control Count Actual')\nplt.legend()\nplt.xlabel('Data Points')\nplt.ylabel('Metrics')\nplt.title('Equivalence Curve for Deterministic and Randomized Alpha-Beta Metrics')\nplt.show()\n\n# Plot the model's structure\nfrom torchviz import make_dot\n\nkan_model_visual = make_dot(kan_model(X), params=dict(kan_model.named_parameters()))\nkan_model_visual.format = 'png'\nkan_model_visual.render('kan_model')\n","block_group":"cfab9ba22c694d699c260229e844f5f3","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=f6f51e1a-d40a-494a-8398-36807e7a81cb' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"b17c53a0a0b34152bf18eee96b171e70","deepnote_execution_queue":[]}}